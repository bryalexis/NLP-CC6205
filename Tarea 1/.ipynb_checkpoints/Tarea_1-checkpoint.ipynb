{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:18:43.301002Z",
     "start_time": "2019-08-21T19:18:43.298037Z"
    }
   },
   "source": [
    "# Tarea 1 - CC6205\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "## Introducción\n",
    "El objetivo general de la tarea consiste en la clasificación de tweets por intensidad de emoción. Específicamente, dado un tweet y una emoción (anger, fear, sadness y joy), se espera crear un sistema capaz de detectar la intensidad de esa emoción en el tweet (low, medium, high).\n",
    "\n",
    "El procedimiento general utilizado durante la tarea es un afinamiento del tokenizador, para transformar los tweets a vectores de una forma tal que la clasificación final fuera satisfactoria en comparación a un baseline. A su vez, se prueban distintos clasificadores de librerias de python como NLTK, convergiendo a uno que entregara mejores resultados.\n",
    "\n",
    "## Trabajo Relacionado\n",
    "El peiper, explicar (Bryan se encarga)\n",
    "\n",
    "## Algoritmos y Representaciones\n",
    "Nuestro programa funciona como sigue a continuación:\n",
    "\n",
    "### Importación de Librerías y Útiles\n",
    "Se utilizarán las librerías *pandas*, *shutil*, *sklearn* y *numpy* en principio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:45:52.624502Z",
     "start_time": "2019-08-21T19:45:48.613907Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los Datasets\n",
    "Estos se obtienen desde el github del curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:45:55.819485Z",
     "start_time": "2019-08-21T19:45:52.626520Z"
    }
   },
   "outputs": [],
   "source": [
    "train = {\n",
    "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/anger-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/fear-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/joy-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/sadness-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'])\n",
    "}\n",
    "\n",
    "target = {\n",
    "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/anger-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/fear-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/joy-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/sadness-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pequeño análisis de los datos\n",
    "Se imprime la cantidad de tweets de cada dataset, según su intensidad de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:45:55.879257Z",
     "start_time": "2019-08-21T19:45:55.826364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 163    163    163\n",
      "low                  161    161    161\n",
      "medium               617    617    617\n",
      "fear \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 270    270    270\n",
      "low                  288    288    288\n",
      "medium               699    699    699\n",
      "joy \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 195    195    195\n",
      "low                  219    219    219\n",
      "medium               488    488    488\n",
      "sadness \n",
      "                       id  tweet  class\n",
      "sentiment_intensity                   \n",
      "high                 197    197    197\n",
      "low                  210    210    210\n",
      "medium               453    453    453\n"
     ]
    }
   ],
   "source": [
    "def get_group_dist(group_name, train):\n",
    "    print(group_name, \"\\n\",\n",
    "          train[group_name].groupby('sentiment_intensity').count())\n",
    "\n",
    "def print_qtweets(dataset):\n",
    "    for key in dataset:\n",
    "        get_group_dist(key, dataset)\n",
    "\n",
    "print_qtweets(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrica de Evaluación\n",
    "Para esta tarea, se utiliza la métrica de evaluación AUROC (también conocida como AUC), la cual se define como el área bajo la curva característica de funcionamiento del receptor. (Explain https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:45:55.891188Z",
     "start_time": "2019-08-21T19:45:55.882211Z"
    }
   },
   "outputs": [],
   "source": [
    "# AUROC\n",
    "def auc(test_set, predicted_set):\n",
    "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
    "    medium_predicted = np.array(\n",
    "        [prediction[1] for prediction in predicted_set])\n",
    "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
    "\n",
    "    high_test = np.where(test_set == 'high', 1.0, 0.0)\n",
    "    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n",
    "    low_test = np.where(test_set == 'low', 1.0, 0.0)\n",
    "\n",
    "    auc_high = roc_auc_score(high_test, high_predicted)\n",
    "    auc_med = roc_auc_score(medium_test, medium_predicted)\n",
    "    auc_low = roc_auc_score(low_test, low_predicted)\n",
    "\n",
    "    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n",
    "             high_test.sum() * auc_high) / (\n",
    "                 low_test.sum() + medium_test.sum() + high_test.sum())\n",
    "    return auc_w    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División del Dataset\n",
    "Esto divide el dataset en un set de training y otro de testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:45:55.901161Z",
     "start_time": "2019-08-21T19:45:55.893181Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset):\n",
    "    # Dividir el dataset en train set y test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset.tweet,\n",
    "        dataset.sentiment_intensity,\n",
    "        shuffle=True,\n",
    "        test_size=0.33)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizadores\n",
    "Para crear los tokens, se utilizan distintos módulos y funcionalidades de variadas librerías. Se utiliza `TweetTokenizer` de la librería `nltk` para crear los tokens base, luego se definen: \n",
    "\n",
    "#### Stopwords Removal\n",
    "Remueve los stopwords de los tokens, así como los símbolos que no aportan mucha utilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def remStopWords(tokens):\n",
    "    newTokens = []\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    stopWords_extended = stopWords | {'.', ',', ':', '+', '-', '(',')',';','\\'','..','...','—', '>','<','\\\\'}\n",
    "    for token in tokens:\n",
    "        if (token not in stopWords_extended) and (token[0:1]!='@'):\n",
    "            newTokens.append(token)\n",
    "    return newTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer\n",
    "Utiliza la stematization para reducir palabras a su raíz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:50:52.114345Z",
     "start_time": "2019-08-21T19:50:52.110384Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "def stemmize(tokens):\n",
    "    ps = PorterStemmer()\n",
    "    stemmedTokens = []\n",
    "    for word in tokens:\n",
    "        stemmedTokens.append(ps.stem(word))\n",
    "    return stemmedTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Hashtags\n",
    "Tras varios experimentos, se deduce que los hashtags no aportan demasiada precisión al programa, sino que incluso lo entorpecían en ocasiones, provocando resultados no deseados. Aún así, parecen ser una importante fuente de información acerca del sentimiento, por lo tanto se decide convertirlo a palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtagToWord(tokens):\n",
    "    newTokens = []\n",
    "    for token in tokens:\n",
    "        newTokens.append(token.replace('#',''))\n",
    "    return newTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer\n",
    "Utiliza la lemmatization para reducir palabras a su raíz, *truncando* las ultimas letras de la palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatize(tokens):\n",
    "    lem = WordNetLemmatizer()\n",
    "    lemmatizedTokens = []\n",
    "    for word in tokens:\n",
    "        lemmatizedTokens.append(lem.lemmatize(word))\n",
    "    return lemmatizedTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer\n",
    "Usando distintas combinaciones de las utilidades ya mencionadas, se crea un tokenizador que puede usar cada una de ellas a elección. También se añade la posibilidad de usar el módulo `mark_negation`, el cual, añade un \\_NEG a todas las palabras que vengan despues de una negación hasta el próximo punto. Por ejemplo:\n",
    "I don't like olives. But I like pizza. -> I don't like_NOT olives_NOT. But I like pizza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.sentiment.util import mark_negation\n",
    "def superTokenize(text, mark_neg, remSW, lem, stem):\n",
    "    tokens = TweetTokenizer().tokenize(text)\n",
    "    if mark_neg:    tokens = mark_negation(tokens)\n",
    "    if remSW:       tokens = remStopWords(tokens)\n",
    "    if lem:         tokens = lemmatize(tokens)\n",
    "    if stem:        tokens = stemmize(tokens) \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir evaluación\n",
    "\n",
    "Esta función imprime la matriz de confusión, el reporte de clasificación y las metricas usadas en la competencia:\n",
    "\n",
    "\n",
    "- `auc`\n",
    "- `kappa`\n",
    "- `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:53:24.009626Z",
     "start_time": "2019-08-21T19:53:24.002646Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaulate(predicted, y_test, labels):\n",
    "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
    "    # entregar el arreglo de clases aprendido por el clasificador. \n",
    "    # (que comunmente, es distinto a ['low', 'medium', 'high'])\n",
    "    predicted_labels = [labels[np.argmax(item)] for item in predicted]\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print('Confusion Matrix for {}:\\n'.format(key))\n",
    "\n",
    "    # Classification Report\n",
    "    print(\n",
    "        confusion_matrix(y_test,\n",
    "                         predicted_labels,\n",
    "                         labels=['low', 'medium', 'high']))\n",
    "\n",
    "    print('\\nClassification Report')\n",
    "    print(\n",
    "        classification_report(y_test,\n",
    "                              predicted_labels,\n",
    "                              labels=['low', 'medium', 'high']))\n",
    "\n",
    "    # AUC\n",
    "    print(\"auc: \", auc(y_test, predicted))\n",
    "\n",
    "    # Kappa\n",
    "    print(\"kappa:\", cohen_kappa_score(y_test, predicted_labels))\n",
    "\n",
    "    # Accuracy\n",
    "    print(\"accuracy:\", accuracy_score(y_test, predicted_labels), \"\\n\")\n",
    "\n",
    "    print('------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar el clasificador para cierto dataset\n",
    "\n",
    "Clasifica un dataset. Retorna el modelo ya entrenado mas sus labels asociadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:53:25.978116Z",
     "start_time": "2019-08-21T19:53:25.973129Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classify(dataset, key):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_dataset(dataset)\n",
    "    text_clf = get_classifier()\n",
    "\n",
    "    # Entrenar el clasificador\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir las probabilidades de intensidad de cada elemento del set de prueba.\n",
    "    predicted = text_clf.predict_proba(X_test)\n",
    "\n",
    "    # Obtener las clases aprendidas.\n",
    "    learned_labels = text_clf.classes_\n",
    "\n",
    "    # Evaluar\n",
    "    evaulate(predicted, y_test, learned_labels)\n",
    "    return text_clf, learned_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar el clasificador por cada dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:53:27.106461Z",
     "start_time": "2019-08-21T19:53:26.933924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for anger:\n",
      "\n",
      "[[  5  42   0]\n",
      " [  7 192  14]\n",
      " [  1  40  10]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.38      0.11      0.17        47\n",
      "      medium       0.70      0.90      0.79       213\n",
      "        high       0.42      0.20      0.27        51\n",
      "\n",
      "    accuracy                           0.67       311\n",
      "   macro avg       0.50      0.40      0.41       311\n",
      "weighted avg       0.61      0.67      0.61       311\n",
      "\n",
      "auc:  0.49430419526882546\n",
      "kappa: 0.11444529624356592\n",
      "accuracy: 0.6655948553054662 \n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Confusion Matrix for fear:\n",
      "\n",
      "[[ 22  69   4]\n",
      " [ 15 186  25]\n",
      " [  0  73  21]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.59      0.23      0.33        95\n",
      "      medium       0.57      0.82      0.67       226\n",
      "        high       0.42      0.22      0.29        94\n",
      "\n",
      "    accuracy                           0.55       415\n",
      "   macro avg       0.53      0.43      0.43       415\n",
      "weighted avg       0.54      0.55      0.51       415\n",
      "\n",
      "auc:  0.46045720264234513\n",
      "kappa: 0.14120736076188778\n",
      "accuracy: 0.5518072289156627 \n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Confusion Matrix for joy:\n",
      "\n",
      "[[ 12  53   1]\n",
      " [ 13 141   3]\n",
      " [  1  39  35]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.46      0.18      0.26        66\n",
      "      medium       0.61      0.90      0.72       157\n",
      "        high       0.90      0.47      0.61        75\n",
      "\n",
      "    accuracy                           0.63       298\n",
      "   macro avg       0.65      0.52      0.53       298\n",
      "weighted avg       0.65      0.63      0.59       298\n",
      "\n",
      "auc:  0.40446943371328126\n",
      "kappa: 0.31108402337018204\n",
      "accuracy: 0.6308724832214765 \n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "Confusion Matrix for sadness:\n",
      "\n",
      "[[ 11  55   0]\n",
      " [ 10 138   9]\n",
      " [  1  46  14]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.50      0.17      0.25        66\n",
      "      medium       0.58      0.88      0.70       157\n",
      "        high       0.61      0.23      0.33        61\n",
      "\n",
      "    accuracy                           0.57       284\n",
      "   macro avg       0.56      0.43      0.43       284\n",
      "weighted avg       0.57      0.57      0.51       284\n",
      "\n",
      "auc:  0.42354064938495906\n",
      "kappa: 0.1468295347336015\n",
      "accuracy: 0.573943661971831 \n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "learned_labels_array = []\n",
    "\n",
    "# Por cada llave en train ('anger', 'fear', 'joy', 'sadness')\n",
    "for key in train:\n",
    "    classifier, learned_labels = classify(train[key], key)\n",
    "    classifiers.append(classifier)\n",
    "    learned_labels_array.append(learned_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:37:43.169737Z",
     "start_time": "2019-08-21T19:37:43.166744Z"
    }
   },
   "source": [
    "## Predecir target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:50:59.474909Z",
     "start_time": "2019-08-21T19:50:59.469921Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_target(dataset, classifier, labels):\n",
    "    # Predecir las probabilidades de intensidad de cada elemento del target set.\n",
    "    predicted = pd.DataFrame(classifier.predict_proba(dataset.tweet), columns=labels)\n",
    "    # Agregar ids\n",
    "    predicted['id'] = dataset.id.values\n",
    "    # Reordenar\n",
    "    predicted = predicted[['id', 'low', 'medium', 'high']]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar la predicción y guardar archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T20:00:10.724762Z",
     "start_time": "2019-08-21T20:00:10.576665Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_target = {}\n",
    "\n",
    "if (not os.path.isdir('./predictions')):\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "else:\n",
    "    # Eliminar predicciones anteriores:\n",
    "    shutil.rmtree('./predictions')\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "for idx, key in enumerate(target):\n",
    "    # Predecir el target set\n",
    "    predicted_target[key] = predict_target(target[key], classifiers[idx],\n",
    "                                           learned_labels_array[idx])\n",
    "    # Guardar predicciones\n",
    "    predicted_target[key].to_csv('./predictions/{}-pred.txt'.format(key),\n",
    "                                 sep='\\t',\n",
    "                                 header=False,\n",
    "                                 index=False)\n",
    "\n",
    "# Crear archivo zip\n",
    "a = shutil.make_archive('predictions', 'zip', './predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
